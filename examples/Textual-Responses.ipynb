{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiGsBj4xlMzY"
      },
      "source": [
        "Welcome to this tutorial! We will look at how to apply aggregation methods to a text response, just imagine: you have received different text answers to the same transcription of the text and you need to somehow solve this problem and get the correct answer. Amazing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MscnHHzgHbZ0"
      },
      "source": [
        "We are going to use some machine learning models and for faster calculating it's better to use GPU. First of all, let's install all the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TOPHiaba9SDD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install pandas\n",
        "%pip install ipyplot\n",
        "%pip install crowd-kit\n",
        "%pip install sentence_transformers\n",
        "%pip install jiwer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vSvvVacZW2w"
      },
      "source": [
        "So, we want somehow to get one correct answer from the several textual responses. Let's deal with that problem with crowd-kit library and see what we can do with it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wmfR76Xu9i55"
      },
      "outputs": [],
      "source": [
        "from crowdkit.datasets import get_datasets_list, load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3-8aqvIaEv9"
      },
      "source": [
        "The load_dataset function returns a pair of elements. The first element is the pandas data frame with the crowdsourced data. The second element is the ground truth dataset, whenever possible. The data frame, or df, has three columns: worker, task, and label. The label is set to 0 if the document is rated as non-relevant by the given annotator in the given task, otherwise, the label will be 1. The ground truth dataset df_gt is a pandas series that contains the correct responses to the tasks put to the index of this series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLDTqE0aIyB6"
      },
      "outputs": [],
      "source": [
        "df, gt = load_dataset('crowdspeech-test-clean')\n",
        "\n",
        "df['text'] = df['text'].str.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omalY7ybo4Ki"
      },
      "source": [
        "Let's see the structure of our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAecNuVL2HaN",
        "outputId": "64041392-f26f-4344-e2b9-c715adac7a9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['task', 'worker', 'text'], dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR5CM1e4G0gG",
        "outputId": "5034cbd2-bb2d-4eba-ff80-c61dd4567c1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "task\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/0.mp3       young fitzooth had been commanded to his mothe...\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/1.mp3       there befell an anxious interview mistress fit...\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/2.mp3       most of all robin thought of his father what w...\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/3.mp3       if for a whim you beggar yourself i cannot sta...\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/4.mp3       but take it whilst i live and wear montfichet'...\n",
              "                                                                                                    ...                        \n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/2615.mp3    it is evident therefore that the present trend...\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/2616.mp3    it is also noticeable that the serviceability ...\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/2617.mp3    consumption becomes a larger element in the st...\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/2618.mp3    among the country population its place is to s...\n",
              "https://tlk.s3.yandex.net/annotation_tasks/librispeech/test-clean/2619.mp3    the result is a great mobility of the labor em...\n",
              "Name: true_label, Length: 2620, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYPa2ZDniEw5"
      },
      "source": [
        "Now let's see how we can solve the aggregation problem with text responses. We will use three methods - ROVER, TextRASA, and TextHRRASA. All these methods solve the same problem - text aggregation - but in different ways. \n",
        "Let's import them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RBEHhOUwYBj9"
      },
      "outputs": [],
      "source": [
        "from crowdkit.aggregation import ROVER\n",
        "from crowdkit.aggregation import TextHRRASA\n",
        "from crowdkit.aggregation import TextRASA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-MUkakUlBFi"
      },
      "source": [
        "At first, we will use Recognizer Output Voting Error Reduction - ROVER. It's a dynamic programming method to align sequences. We need to determine the tokenizer and detokenizer functions. For the tokenizer, we will split a sentence by spaces and for the detokenizer we will glue the words into a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGy2nWqceYaL"
      },
      "outputs": [],
      "source": [
        "tokenizer = lambda s: s.split(' ')\n",
        "detokenizer = lambda tokens: ' '.join(tokens)\n",
        "\n",
        "result_ROVER = ROVER(tokenizer, detokenizer).fit_predict(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nl9JNhw-PKj"
      },
      "source": [
        "Next, we will try TextHRRASA. We need to determine the encoder - a callable that takes a text and returns a NumPy array containing the corresponding embedding. For that, we will use the model from sentence_transformers. The model.encode returns the embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iY4MGGY7fhFW"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "result_TextHRRASA = TextHRRASA(encoder = model.encode).fit_predict(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2fpVsQPBQee"
      },
      "source": [
        "The last method is RASA. Do the same as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzIHFkMPxs98"
      },
      "outputs": [],
      "source": [
        "from crowdkit.aggregation import TextRASA\n",
        "\n",
        "result_TextRASA = TextRASA(encoder=model.encode).fit_predict(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVeqVuTPBZaZ"
      },
      "source": [
        " Let's compare the results of these methods - we will use word error rate (WER) from jiwer. The less the WER metric the better-predicted word sequence we did. Let's see the difference!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HnE7fdYBZFi",
        "outputId": "8bb73d05-1150-4f34-9a4f-0be12e9fe44a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The WER of TextRASA - 0.0907894234804838\n",
            "The WER of TextHRRASA - 0.09415696009165553\n",
            "The WER of ROVER - 0.07017374889239897\n"
          ]
        }
      ],
      "source": [
        "from jiwer import wer\n",
        "\n",
        "input_TextRASA = list()\n",
        "target_TextRASA = list()\n",
        "\n",
        "#Making target and input lists from TextRASA method and golden set\n",
        "for i in gt.index:\n",
        "  input_TextRASA.append(gt.loc[i])\n",
        "  target_TextRASA.append(result_TextRASA['output'].loc[i])\n",
        "\n",
        "print('The WER of TextRASA -', wer(target_TextRASA, input_TextRASA))\n",
        "\n",
        "input_TextHRRASA = list()\n",
        "target_TextHRRASA = list()\n",
        "\n",
        "#Making target and input lists from TextHRRASA method and golden set\n",
        "for i in gt.index:\n",
        "  input_TextHRRASA.append(gt.loc[i])\n",
        "  target_TextHRRASA.append(result_TextHRRASA['output'].loc[i])\n",
        "\n",
        "print('The WER of TextHRRASA -', wer(target_TextHRRASA, input_TextHRRASA))\n",
        "\n",
        "\n",
        "input_ROVER = list()\n",
        "target_ROVER = list()\n",
        "\n",
        "#Making target and input lists from ClosestToAverage method and golden set\n",
        "for i in gt.index:\n",
        "  input_ROVER.append(gt.loc[i])\n",
        "  target_ROVER.append(result_ROVER.loc[i])\n",
        "# найти встроенный способ найти индекс\n",
        "print('The WER of ROVER -', wer(target_ROVER, input_ROVER))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6-bMosdquIJ"
      },
      "source": [
        "See? We got extremely excellent results by all methods, as expected, the Rover method gave a slightly better result. Thus, you have solved the problem posed - text aggregation - with the help of the crowd-kit library!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
